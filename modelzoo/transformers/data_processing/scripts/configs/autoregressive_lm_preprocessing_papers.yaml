##############################################################
## Autoregressive LM Preprocessing Parameters
##############################################################

setup:
    input_dir: "path/to/dir/containing/jsonlfiles."
    output_dir: "path/to/save/tokenized/output"
    processes: 1
    dataset_processor: "LMDataPreprocessor"

processing:
    tokenizer_type: "HuggingFaceTokenizer"
    tokenizer_type: "NeoXTokenizer"
    encoder_file: "/path/to/tokenizer.json"

    max_seq_length: 2048
    short_seq_prob: 0.0

    output_name: "examples"
    files_per_record: 100
    write_in_batch: True
    max_chunk_size: 256 #Chunk size in kB
    write_remainder: True
    resume_from_checkpoint: False
    display_pbar: True
    seed: 0

dataset:
    use_ftfy: True
    ftfy_normalizer: "NFC"
    wikitext_detokenize: False

    jsonl_key: "text"
    pack_sequences: True
